---
title: Skalierbarkeit
description: Skalierbarkeit
ms.assetid: 39327621-b536-4494-9319-9e9d4f534123
keywords:
- Skalierbarkeit
- Remote Prozedur Aufruf RPC, bewährte Methoden, Skalierbarkeit
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: 0728e35d9c9b27494014363c448be9965e39eea7
ms.sourcegitcommit: 2d531328b6ed82d4ad971a45a5131b430c5866f7
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 09/16/2019
ms.locfileid: "103856736"
---
# <a name="scalability"></a><span data-ttu-id="483a7-105">Skalierbarkeit</span><span class="sxs-lookup"><span data-stu-id="483a7-105">Scalability</span></span>

<span data-ttu-id="483a7-106">Der Begriff "Skalierbarkeit" wird häufig missbraucht.</span><span class="sxs-lookup"><span data-stu-id="483a7-106">The term, scalability, is often misused.</span></span> <span data-ttu-id="483a7-107">In diesem Abschnitt wird eine Dual Definition bereitgestellt:</span><span class="sxs-lookup"><span data-stu-id="483a7-107">For this section, a dual definition is provided:</span></span>

-   <span data-ttu-id="483a7-108">Skalierbarkeit ist die Möglichkeit, die verfügbare Verarbeitungsleistung auf einem Multiprozessorsystem (2, 4, 8, 32 oder mehr Prozessoren) vollständig zu nutzen.</span><span class="sxs-lookup"><span data-stu-id="483a7-108">Scalability is the ability to fully utilize available processing power on a multiprocessor system (2, 4, 8, 32, or more processors).</span></span>
-   <span data-ttu-id="483a7-109">Skalierbarkeit ist die Fähigkeit, eine große Anzahl von Clients zu bedienen.</span><span class="sxs-lookup"><span data-stu-id="483a7-109">Scalability is the ability to service a large number of clients.</span></span>

<span data-ttu-id="483a7-110">Diese beiden verknüpften Definitionen werden im Allgemeinen als zentrales *hochskalieren* bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="483a7-110">These two related definitions are commonly referred to as *scaling up*.</span></span> <span data-ttu-id="483a7-111">Am Ende dieses Themas finden Sie Tipps zum horizontalen hoch *skalieren*.</span><span class="sxs-lookup"><span data-stu-id="483a7-111">The end of this topic provides tips about *scaling out*.</span></span>

<span data-ttu-id="483a7-112">Diese Erörterung konzentriert sich ausschließlich auf das Schreiben skalierbarer Server, nicht auf skalierbare Clients, da skalierbare Server häufiger Anforderungen sind.</span><span class="sxs-lookup"><span data-stu-id="483a7-112">This discussion focuses exclusively on writing scalable servers, not scalable clients, because scalable servers are more common requirements.</span></span> <span data-ttu-id="483a7-113">In diesem Abschnitt wird auch die Skalierbarkeit nur im Kontext von RPC-und RPC-Servern behandelt.</span><span class="sxs-lookup"><span data-stu-id="483a7-113">This section also addresses scalability in the context of RPC and RPC servers only.</span></span> <span data-ttu-id="483a7-114">Bewährte Methoden für die Skalierbarkeit, wie z. b. das Reduzieren von Konflikten, das Vermeiden häufiger Cache Fehler an globalen Speicherorten oder die Vermeidung von falsch Freigaben, werden hier nicht erläutert.</span><span class="sxs-lookup"><span data-stu-id="483a7-114">Best practices for scalability, such as reducing contention, avoiding frequent cache misses on global memory locations, or avoiding false sharing, are not discussed here.</span></span>

## <a name="rpc-threading-model"></a><span data-ttu-id="483a7-115">RPC-Threading Modell</span><span class="sxs-lookup"><span data-stu-id="483a7-115">RPC Threading Model</span></span>

<span data-ttu-id="483a7-116">Wenn ein RPC-Aufruf von einem Server empfangen wird, wird die Server Routine (Manager-Routine) in einem Thread aufgerufen, der von RPC bereitgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="483a7-116">When an RPC call is received by a server, the server routine (manager routine) is called on a thread supplied by RPC.</span></span> <span data-ttu-id="483a7-117">RPC verwendet einen adaptiven Thread Pool, der zunimmt und abnimmt, wenn die Arbeitsauslastung zunimmt.</span><span class="sxs-lookup"><span data-stu-id="483a7-117">RPC uses an adaptive thread pool that increases and decreases as workload fluctuates.</span></span> <span data-ttu-id="483a7-118">Ab Windows 2000 ist der Kern des RPC-Thread Pools ein Abschlussport.</span><span class="sxs-lookup"><span data-stu-id="483a7-118">Starting with Windows 2000, the core of the RPC thread pool is a completion port.</span></span> <span data-ttu-id="483a7-119">Der Abschlussport und seine Verwendung durch RPC sind auf Server Routinen mit Null bis zu niedrigem Konflikt optimiert.</span><span class="sxs-lookup"><span data-stu-id="483a7-119">The completion port and its usage by RPC are tuned for zero to low contention server routines.</span></span> <span data-ttu-id="483a7-120">Dies bedeutet, dass der RPC-Thread Pool die Anzahl der Arbeitsthreads aggressiv erhöht, wenn einige blockiert werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-120">This means that the RPC thread pool aggressively increases the number of servicing threads if some become blocked.</span></span> <span data-ttu-id="483a7-121">Es wird auf die Annahme angewendet, dass die Blockierung selten vorkommt, und wenn ein Thread blockiert wird, ist dies eine vorübergehende Bedingung, die schnell aufgelöst werden kann.</span><span class="sxs-lookup"><span data-stu-id="483a7-121">It operates on the presumption that blocking is rare, and if a thread gets blocked, this is a temporary condition that is quickly resolved.</span></span> <span data-ttu-id="483a7-122">Dieser Ansatz ermöglicht die Effizienz für Server mit geringem Konflikt.</span><span class="sxs-lookup"><span data-stu-id="483a7-122">This approach enables efficiency for low contention servers.</span></span> <span data-ttu-id="483a7-123">Beispielsweise wird ein void-RPC-Server, der auf einem Server mit acht Prozessoren mit 550 MHz ausgeführt wird und auf den über eine hoch Geschwindigkeits System Area Network (San) zugegriffen wird, über 30.000 void-Aufrufe pro Sekunde von über 200 Remote Clients bedient.</span><span class="sxs-lookup"><span data-stu-id="483a7-123">For example, a void call RPC server operating on an eight-processor 550MHz server accessed over a high speed system area network (SAN) serves over 30,000 void calls per second from over 200 remote clients.</span></span> <span data-ttu-id="483a7-124">Dies entspricht mehr als 108 Millionen Aufrufen pro Stunde.</span><span class="sxs-lookup"><span data-stu-id="483a7-124">This represents more than 108 million calls per hour.</span></span>

<span data-ttu-id="483a7-125">Das Ergebnis ist, dass der aggressive Thread Pool tatsächlich auf den Weg kommt, wenn die Konflikte auf dem Server hoch sind.</span><span class="sxs-lookup"><span data-stu-id="483a7-125">The result is that the aggressive thread pool actually gets in the way when contention on the server is high.</span></span> <span data-ttu-id="483a7-126">Stellen Sie sich zur Veranschaulichung einen Hochleistungsserver vor, der für den Remote Zugriff auf Dateien verwendet wird.</span><span class="sxs-lookup"><span data-stu-id="483a7-126">To illustrate, imagine a heavy-duty server used to remotely access files.</span></span> <span data-ttu-id="483a7-127">Angenommen der Server übernimmt den einfachsten Ansatz: die Datei wird einfach synchron in dem Thread gelesen/geschrieben, auf dem die Server Routine von RPC aufgerufen wird.</span><span class="sxs-lookup"><span data-stu-id="483a7-127">Assume the server adopts the most straightforward approach: it simply reads/writes the file synchronously on the thread on which that RPC invokes the server routine.</span></span> <span data-ttu-id="483a7-128">Angenommen, wir verfügen über einen Server mit vier Prozessoren, der viele Clients bedient.</span><span class="sxs-lookup"><span data-stu-id="483a7-128">Also, assume we have a four-processor server serving many clients.</span></span>

<span data-ttu-id="483a7-129">Der Server beginnt mit fünf Threads (Dies variiert tatsächlich, aber fünf Threads werden aus Gründen der Einfachheit verwendet).</span><span class="sxs-lookup"><span data-stu-id="483a7-129">The server will start with five threads (this actually varies, but five threads is used for simplicity).</span></span> <span data-ttu-id="483a7-130">Nachdem RPC den ersten RPC-Aufruf übernommen hat, sendet er den Aufruf an die Server Routine, und die Server Routine gibt den e/a-Vorgang aus.</span><span class="sxs-lookup"><span data-stu-id="483a7-130">Once RPC picks up the first RPC call, it dispatches the call to the server routine, and the server routine issues the I/O.</span></span> <span data-ttu-id="483a7-131">In den meisten Fällen wird der Dateicache nicht ausgeführt, und das warten auf das Ergebnis wird blockiert.</span><span class="sxs-lookup"><span data-stu-id="483a7-131">Infrequently, it misses the file cache and then blocks waiting for the result.</span></span> <span data-ttu-id="483a7-132">Sobald es blockiert wird, wird der fünfte Thread freigegeben, um eine Anforderung zu übernehmen, und ein sechster Thread wird als Hot Standby erstellt.</span><span class="sxs-lookup"><span data-stu-id="483a7-132">As soon as it blocks, the fifth thread is released to pick up a request, and a sixth thread is created as a hot standby.</span></span> <span data-ttu-id="483a7-133">Wenn bei jedem zehnten e/a-Vorgang der Cache fehlschlägt und für 100 Millisekunden (einen willkürlichen Uhrzeitwert) blockiert wird und vorausgesetzt wird, dass der Server mit vier Prozessoren ungefähr 20.000 Anrufe pro Sekunde bedient (5.000 Anrufe pro Prozessor), würde eine vereinfachte Modellierung Vorhersagen, dass jeder Prozessor ungefähr 50 Threads erzeugt.</span><span class="sxs-lookup"><span data-stu-id="483a7-133">Assuming each tenth I/O operation misses the cache and will block for 100 milliseconds (an arbitrary time value), and assuming the four-processor server serves about 20,000 calls per second (5,000 calls per processor), a simplistic modeling would predict that each processor will spawn approximately 50 threads.</span></span> <span data-ttu-id="483a7-134">Dabei wird davon ausgegangen, dass ein-Vorgang blockiert wird, der alle 2 Millisekunden blockiert wird, und nach 100 Millisekunden wird der erste Thread erneut freigegeben, sodass sich der Pool bei ungefähr 200 Threads (50 pro Prozessor) stabilisiert.</span><span class="sxs-lookup"><span data-stu-id="483a7-134">This assumes a call that will block comes every 2 milliseconds, and after 100 milliseconds the first thread is freed again so the pool will stabilize at about 200 threads (50 per processor).</span></span>

<span data-ttu-id="483a7-135">Das tatsächliche Verhalten ist komplizierter, da die große Anzahl von Threads zusätzliche Kontextwechsel zur Verlangsamung des Servers verursacht und auch die Rate der Erstellung neuer Threads verlangsamt, aber die grundlegende Idee ist eindeutig.</span><span class="sxs-lookup"><span data-stu-id="483a7-135">The actual behavior is more complicated, as the high number of threads will cause extra context switches which slow the server, and also slow the rate of creation of new threads, but the basic idea is clear.</span></span> <span data-ttu-id="483a7-136">Die Anzahl der Threads wird schnell beschleunigt, wenn Threads auf dem Server blockieren und auf etwas (e/a-Vorgänge oder Zugriff auf eine Ressource) warten.</span><span class="sxs-lookup"><span data-stu-id="483a7-136">The number of threads goes up quickly as threads on the server start blocking and waiting for something (be it an I/O, or access to a resource).</span></span>

<span data-ttu-id="483a7-137">RPC und der Abschlussport, der eingehende Anforderungen Gates, wird versuchen, die Anzahl der verwendbaren RPC-Threads auf dem Server so zu verwalten, dass Sie mit der Anzahl der Prozessoren auf dem Computer identisch sind.</span><span class="sxs-lookup"><span data-stu-id="483a7-137">RPC and the completion port that gates incoming requests will try to maintain the number of usable RPC threads in the server to be equal to the number of processors on the machine.</span></span> <span data-ttu-id="483a7-138">Dies bedeutet, dass auf einem Server mit vier Prozessoren, sobald ein Thread zu RPC zurückkehrt, der fünfte Thread nicht in der Lage ist, eine neue Anforderung zu übernehmen, und sich stattdessen im aktiven Standbymodus befindet, wenn einer der aktuell verwendbaren Threads blockiert wird.</span><span class="sxs-lookup"><span data-stu-id="483a7-138">This means that on a four-processor server, once a thread returns to RPC, if there are four or more usable RPC threads, the fifth thread is not allowed to pick up a new request, and instead will sit in a hot standby state in case one of the currently usable threads blocks.</span></span> <span data-ttu-id="483a7-139">Wenn der fünfte Thread lange genug als Hot Standby wartet, ohne dass die Anzahl der verwendbaren RPC-Threads unter der Anzahl der Prozessoren liegt, wird er freigegeben, d. h., der Thread Pool wird verringert.</span><span class="sxs-lookup"><span data-stu-id="483a7-139">If the fifth thread waits long enough as a hot standby without the number of usable RPC threads dropping below the number of processors, it will be released, that is, the thread pool will decrease.</span></span>

<span data-ttu-id="483a7-140">Stellen Sie sich einen Server mit vielen Threads vor.</span><span class="sxs-lookup"><span data-stu-id="483a7-140">Imagine a server with many threads.</span></span> <span data-ttu-id="483a7-141">Wie bereits erläutert, wird ein RPC-Server mit vielen Threads beendet, aber nur, wenn die Threads häufig blockiert werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-141">As previously explained, an RPC server ends up with many threads, but only if the threads block often.</span></span> <span data-ttu-id="483a7-142">Auf einem Server, auf dem Threads oft blockieren, wird ein Thread, der zu RPC zurückkehrt, bald aus der Liste der aktiven standbyvorgänge entfernt, da alle gegenwärtig verwendbaren Threads blockiert werden und eine Anforderung zur Verarbeitung erhalten.</span><span class="sxs-lookup"><span data-stu-id="483a7-142">On a server where threads often block, a thread that returns to RPC is soon taken out of the hot standby list, because all currently usable threads block, and is given a request to process.</span></span> <span data-ttu-id="483a7-143">Wenn ein Thread blockiert wird, wechselt der Thread Verteiler im Kernel in den Kontext zu einem anderen Thread.</span><span class="sxs-lookup"><span data-stu-id="483a7-143">When a thread blocks, the thread dispatcher in the kernel switches context to another thread.</span></span> <span data-ttu-id="483a7-144">Dieser Kontextwechsel selbst beansprucht CPU-Zyklen.</span><span class="sxs-lookup"><span data-stu-id="483a7-144">This context switch by itself consumes CPU cycles.</span></span> <span data-ttu-id="483a7-145">Der nächste Thread führt einen anderen Code aus, greift auf verschiedene Datenstrukturen zu und verfügt über einen anderen Stapel. Dies bedeutet, dass die Speicher Cache-Treffer Rate (L1-und L2-Caches) erheblich geringer ist, was zu einer langsameren Ausführung führt.</span><span class="sxs-lookup"><span data-stu-id="483a7-145">The next thread will be executing different code, accessing different data structures, and will have a different stack, which means the memory cache hit rate (the L1 and L2 caches) will be much lower, resulting in slower execution.</span></span> <span data-ttu-id="483a7-146">Die zahlreichen Threads, die gleichzeitig ausgeführt werden, erhöhen Konflikte für vorhandene Ressourcen, z. b. Heap, kritische Abschnitte im Servercode usw.</span><span class="sxs-lookup"><span data-stu-id="483a7-146">The numerous threads executing simultaneously increases contention for existing resources, such as heap, critical sections in the server code, and so on.</span></span> <span data-ttu-id="483a7-147">Dadurch erhöht sich der Konflikt als Konvois im Ressourcen Formular.</span><span class="sxs-lookup"><span data-stu-id="483a7-147">This further increases contention as convoys on resources form.</span></span> <span data-ttu-id="483a7-148">Wenn nicht genügend Arbeitsspeicher verfügbar ist, verursacht der Arbeitsspeicher Mangel, der durch die große und wachsende Anzahl von Threads verursacht wird, Seiten Fehler, wodurch die Rate, mit der der Thread blockiert wird, weiter erhöht wird und noch mehr Threads erstellt werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-148">If memory is low, the memory pressure exerted by the large and growing number of threads will cause page faults, which further increase the rate at which the threads block, and cause even more threads to be created.</span></span> <span data-ttu-id="483a7-149">Je nachdem, wie oft es blockiert wird und wie viel physischer Arbeitsspeicher verfügbar ist, kann sich der Server entweder auf einer niedrigeren Leistungsstufe mit einer hohen Kontextwechsel Rate stabilisieren, oder es kann zu dem Punkt, an dem er nur wiederholt auf die Festplatte und den Kontextwechsel zugreift, ohne wirkliche Arbeitsschritte beeinträchtigt werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-149">Depending on how often it blocks and how much physical memory is available, the server may either stabilize at some lower level of performance with a high context switch rate, or it may deteriorate to the point where it is only repeatedly accessing the hard disk and context switching without performing any actual work.</span></span> <span data-ttu-id="483a7-150">Diese Situation wird natürlich nicht unter Licht Arbeitsauslastung angezeigt, aber eine hohe Arbeitsauslastung bringt das Problem schnell auf die Oberfläche.</span><span class="sxs-lookup"><span data-stu-id="483a7-150">This situation will not show under light workload, of course, but a heavy workload quickly brings the problem to the surface.</span></span>

<span data-ttu-id="483a7-151">Wie kann dies verhindert werden?</span><span class="sxs-lookup"><span data-stu-id="483a7-151">How can this be prevented?</span></span> <span data-ttu-id="483a7-152">Wenn die Blockierung von Threads zu erwarten ist, deklarieren Sie Aufrufe als asynchron, und sobald die Anforderung in die Server Routine eintritt, stellen Sie Sie in eine Warteschlange für einen Pool von Arbeitsthreads, die die asynchronen Funktionen des e/a-Systems und/oder RPC verwenden.</span><span class="sxs-lookup"><span data-stu-id="483a7-152">If threads are expected to block, declare calls as asynchronous, and once the request enters the server routine, queue it to a pool of worker threads that use the asynchronous capabilities of the I/O system and/or RPC.</span></span> <span data-ttu-id="483a7-153">Wenn der Server seinerseits RPC-Aufrufe durchführt, machen Sie diese asynchron, und stellen Sie sicher, dass die Warteschlange nicht zu groß wird.</span><span class="sxs-lookup"><span data-stu-id="483a7-153">If the server is in turn making RPC calls make those asynchronous, and make sure the queue does not grow too large.</span></span> <span data-ttu-id="483a7-154">Wenn die Server Routine Datei-e/a-Vorgänge ausführt, verwenden Sie asynchrone Datei-e/a-Vorgänge, um mehrere Anforderungen an das e/a-System in die Warteschlange zu stellen und die Ergebnisse in die Warteschlange aufzunehmen.</span><span class="sxs-lookup"><span data-stu-id="483a7-154">If the server routine is performing file I/O, use asynchronous file I/O to queue multiple requests to the I/O system and have only a few threads queue them and pick up the results.</span></span> <span data-ttu-id="483a7-155">Wenn die Server Routine Netzwerk-e/a-Vorgänge durchführen, verwenden Sie die asynchronen Funktionen des Systems, um die Anforderungen auszugeben, und übernehmen Sie die Antworten asynchron, und verwenden Sie so wenige Threads wie möglich.</span><span class="sxs-lookup"><span data-stu-id="483a7-155">If the server routine is doing network I/O, again, use the asynchronous capabilities of the system to issue the requests and pick up the replies asynchronously, and use as few threads as possible.</span></span> <span data-ttu-id="483a7-156">Wenn die e/a-Vorgänge abgeschlossen sind oder der vom Server ausgeführte RPC-Aufruf abgeschlossen ist, vervollständigen Sie den asynchronen RPC-Aufruf, der die Anforderung übermittelt hat.</span><span class="sxs-lookup"><span data-stu-id="483a7-156">When the I/O is done, or the RPC call the server made is complete, complete the asynchronous RPC call that delivered the request.</span></span> <span data-ttu-id="483a7-157">Auf diese Weise kann der Server mit möglichst wenigen Threads ausgeführt werden, wodurch die Leistung und die Anzahl der Clients, die ein Server bedienen kann, erhöht werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-157">This will enable the server to run with as few threads as possible, which increases the performance and the number of clients a server can service.</span></span>

## <a name="scale-out"></a><span data-ttu-id="483a7-158">Aufskalieren</span><span class="sxs-lookup"><span data-stu-id="483a7-158">Scale Out</span></span>

<span data-ttu-id="483a7-159">RPC kann so konfiguriert werden, dass er mit Netzwerk Lastenausgleich (NLB) funktioniert, wenn der Netzwerk Lastenausgleich so konfiguriert ist, dass alle Anforderungen von einer bestimmten Client Adresse an denselben Server weitergeleitet werden.</span><span class="sxs-lookup"><span data-stu-id="483a7-159">RPC can be configured to work with Network Load Balancing (NLB) if NLB is configured such that all requests from a given client address go to the same server.</span></span> <span data-ttu-id="483a7-160">Da jeder RPC-Client einen Verbindungspool öffnet (Weitere Informationen finden Sie unter [RPC und das Netzwerk](rpc-and-the-network.md)), ist es von entscheidender Bedeutung, dass alle Verbindungen aus dem Pool des angegebenen Clients auf demselben Server Computer enden.</span><span class="sxs-lookup"><span data-stu-id="483a7-160">Because each RPC client opens a connection pool (for more information, see [RPC and the Network](rpc-and-the-network.md)), it is essential that all connections from the pool of the given client end up on the same server computer.</span></span> <span data-ttu-id="483a7-161">Solange diese Bedingung erfüllt ist, kann ein NLB-Cluster so konfiguriert werden, dass er als ein großer RPC-Server mit möglicherweise hervorragender Skalierbarkeit funktioniert.</span><span class="sxs-lookup"><span data-stu-id="483a7-161">As long as this condition is met, an NLB cluster can be configured to function as one large RPC server with potentially excellent scalability.</span></span>

 

 




