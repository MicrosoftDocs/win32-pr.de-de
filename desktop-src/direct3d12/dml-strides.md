---
title: Verwenden von Schritten zum Ausdrücken von Auffüll-und Speicher Layout
description: Directml-Tensoren werden von Eigenschaften beschrieben, die als *Größen* und *Fortschritte* des Mandanten bezeichnet werden.
ms.custom: Windows 10 May 2019 Update
ms.localizationpriority: high
ms.topic: article
ms.date: 04/19/2019
ms.openlocfilehash: b944b1a2600febe27f209bffcc0e355c6a9fc7db
ms.sourcegitcommit: cba7f424a292fd7f3a8518947b9466439b455419
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 11/23/2019
ms.locfileid: "104548680"
---
# <a name="using-strides-to-express-padding-and-memory-layout"></a><span data-ttu-id="01115-103">Verwenden von Schritten zum Ausdrücken von Auffüll-und Speicher Layout</span><span class="sxs-lookup"><span data-stu-id="01115-103">Using strides to express padding and memory layout</span></span>

<span data-ttu-id="01115-104">Directml-Tensoren &mdash; , die durch Direct3D 12-Puffer unterstützt werden, &mdash; werden durch Eigenschaften, die als *Größen* und *Fortschritte* des Mandanten bezeichnet werden, beschrieben.</span><span class="sxs-lookup"><span data-stu-id="01115-104">DirectML tensors&mdash;which are are backed by Direct3D 12 buffers&mdash;are described by properties known as the *sizes* and the *strides* of the tensor.</span></span> <span data-ttu-id="01115-105">Die Tensor- *Größen* beschreiben die logischen Dimensionen des Mandanten.</span><span class="sxs-lookup"><span data-stu-id="01115-105">The tensor's *sizes* describe the logical dimensions of the tensor.</span></span> <span data-ttu-id="01115-106">Ein 2D-tensorflow kann z. b. eine Höhe von 2 und eine Breite von 3 haben.</span><span class="sxs-lookup"><span data-stu-id="01115-106">For example, a 2D tensor might have a height of 2 and a width of 3.</span></span> <span data-ttu-id="01115-107">Logisch hat der tensorflow 6 unterschiedliche Elemente, obwohl die Größen nicht angeben, wie diese Elemente im Arbeitsspeicher gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="01115-107">Logically, the tensor has 6 distinct elements, although the sizes don't specify how those elements are stored in memory.</span></span> <span data-ttu-id="01115-108">Die *Schritte* des Mandanten beschreiben das physische Speicher Layout der Tensor-Elemente.</span><span class="sxs-lookup"><span data-stu-id="01115-108">The tensor's *strides* describe the physical memory layout of the tensor's elements.</span></span>

## <a name="two-dimensional-2d-arrays"></a><span data-ttu-id="01115-109">Zweidimensionale (2D) Arrays</span><span class="sxs-lookup"><span data-stu-id="01115-109">Two-dimensional (2D) arrays</span></span>

<span data-ttu-id="01115-110">Angenommen, ein 2D-tensorflow hat eine Höhe von 2 und eine Breite von 3. die Daten bestehen aus Textzeichen.</span><span class="sxs-lookup"><span data-stu-id="01115-110">Consider a 2D tensor that has a height of 2 and a width of 3; the data comprises textual characters.</span></span> <span data-ttu-id="01115-111">In C/C++ kann dies mit einem mehrdimensionalen Array ausgedrückt werden.</span><span class="sxs-lookup"><span data-stu-id="01115-111">In C/C++, this might be expressed using a multi-dimensional array.</span></span>

```cpp
constexpr int rows = 2;
constexpr int columns = 3;
char tensor[rows][columns];
tensor[0][0] = 'A';
tensor[0][1] = 'B';
tensor[0][2] = 'C';
tensor[1][0] = 'D';
tensor[1][1] = 'E';
tensor[1][2] = 'F';
```

<span data-ttu-id="01115-112">Die logische Ansicht des obigen Tensors wird unten dargestellt.</span><span class="sxs-lookup"><span data-stu-id="01115-112">The logical view of the above tensor is visualized below.</span></span>

```console
A B C
D E F
```

<span data-ttu-id="01115-113">In C/C++ wird ein mehrdimensionales Array in Zeilen Hauptreihenfolge gespeichert.</span><span class="sxs-lookup"><span data-stu-id="01115-113">In C/C++, a multi-dimensional array is stored in row-major order.</span></span> <span data-ttu-id="01115-114">Das heißt, dass die aufeinander folgenden Elemente entlang der Width-Dimension im linearen Speicherbereich zusammenhängend gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="01115-114">In other words, the consecutive elements along the width dimension are stored contiguously in linear memory space.</span></span>

<span data-ttu-id="01115-115">Offset:</span><span class="sxs-lookup"><span data-stu-id="01115-115">Offset:</span></span>|<span data-ttu-id="01115-116">0</span><span class="sxs-lookup"><span data-stu-id="01115-116">0</span></span>|<span data-ttu-id="01115-117">1</span><span class="sxs-lookup"><span data-stu-id="01115-117">1</span></span>|<span data-ttu-id="01115-118">2</span><span class="sxs-lookup"><span data-stu-id="01115-118">2</span></span>|<span data-ttu-id="01115-119">3</span><span class="sxs-lookup"><span data-stu-id="01115-119">3</span></span>|<span data-ttu-id="01115-120">4</span><span class="sxs-lookup"><span data-stu-id="01115-120">4</span></span>|<span data-ttu-id="01115-121">5</span><span class="sxs-lookup"><span data-stu-id="01115-121">5</span></span>
-|-|-|-|-|-|-
<span data-ttu-id="01115-122">Wert:</span><span class="sxs-lookup"><span data-stu-id="01115-122">Value:</span></span>|<span data-ttu-id="01115-123">A</span><span class="sxs-lookup"><span data-stu-id="01115-123">A</span></span>|<span data-ttu-id="01115-124">B</span><span class="sxs-lookup"><span data-stu-id="01115-124">B</span></span>|<span data-ttu-id="01115-125">C</span><span class="sxs-lookup"><span data-stu-id="01115-125">C</span></span>|<span data-ttu-id="01115-126">D</span><span class="sxs-lookup"><span data-stu-id="01115-126">D</span></span>|<span data-ttu-id="01115-127">E</span><span class="sxs-lookup"><span data-stu-id="01115-127">E</span></span>|<span data-ttu-id="01115-128">F</span><span class="sxs-lookup"><span data-stu-id="01115-128">F</span></span>

<span data-ttu-id="01115-129">Der *Stride* -Wert einer Dimension ist die Anzahl der zu über springenden Elemente, um auf das nächste Element in dieser Dimension zuzugreifen.</span><span class="sxs-lookup"><span data-stu-id="01115-129">The *stride* of a dimension is the number of elements to skip in order to access the next element in that dimension.</span></span> <span data-ttu-id="01115-130">Mit Schritten wird das Layout des Tensors im Arbeitsspeicher ausgedrückt.</span><span class="sxs-lookup"><span data-stu-id="01115-130">Strides express the layout of the tensor in memory.</span></span> <span data-ttu-id="01115-131">Bei einer Zeilen Hauptreihenfolge ist der Stride der Width-Dimension immer 1, da angrenzende Elemente entlang der Dimension zusammenhängend gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="01115-131">With a row-major order, the stride of the width dimension is always 1, since adjacent elements along the dimension are stored contiguously.</span></span> <span data-ttu-id="01115-132">Der Schritt der Height-Dimension hängt von der Größe der Width-Dimension ab. im obigen Beispiel ist der Abstand zwischen aufeinander folgenden Elementen entlang der Height-Dimension (z. b. A bis D) gleich der Breite des Tensors (in diesem Beispiel 3).</span><span class="sxs-lookup"><span data-stu-id="01115-132">The stride of the height dimension depends on the size of the width dimension; in the above example, the distance between consecutive elements along the height dimension (for example, A to D) is equal to the width of the tensor (which is 3 in this example).</span></span>

<span data-ttu-id="01115-133">Um ein anderes Layout zu veranschaulichen, sollten Sie die Spalten Hauptreihenfolge in Erwägung gezogen</span><span class="sxs-lookup"><span data-stu-id="01115-133">To illustrate a different layout, consider column-major order.</span></span> <span data-ttu-id="01115-134">Das heißt, dass die aufeinander folgenden Elemente entlang der Height-Dimension im linearen Speicherbereich zusammenhängend gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="01115-134">In other words, the consecutive elements along the height dimension are stored contiguously in linear memory space.</span></span> <span data-ttu-id="01115-135">In diesem Fall ist der Höhen Sprung immer 1, und der Width-Stride ist 2 (die Größe der Height-Dimension).</span><span class="sxs-lookup"><span data-stu-id="01115-135">In this case, the height-stride is always 1, and the width-stride is 2 (the size of the height dimension).</span></span>

<span data-ttu-id="01115-136">Offset:</span><span class="sxs-lookup"><span data-stu-id="01115-136">Offset:</span></span>|<span data-ttu-id="01115-137">0</span><span class="sxs-lookup"><span data-stu-id="01115-137">0</span></span>|<span data-ttu-id="01115-138">1</span><span class="sxs-lookup"><span data-stu-id="01115-138">1</span></span>|<span data-ttu-id="01115-139">2</span><span class="sxs-lookup"><span data-stu-id="01115-139">2</span></span>|<span data-ttu-id="01115-140">3</span><span class="sxs-lookup"><span data-stu-id="01115-140">3</span></span>|<span data-ttu-id="01115-141">4</span><span class="sxs-lookup"><span data-stu-id="01115-141">4</span></span>|<span data-ttu-id="01115-142">5</span><span class="sxs-lookup"><span data-stu-id="01115-142">5</span></span>
-|-|-|-|-|-|-
<span data-ttu-id="01115-143">Wert:</span><span class="sxs-lookup"><span data-stu-id="01115-143">Value:</span></span>|<span data-ttu-id="01115-144">Ein</span><span class="sxs-lookup"><span data-stu-id="01115-144">A</span></span>|<span data-ttu-id="01115-145">D</span><span class="sxs-lookup"><span data-stu-id="01115-145">D</span></span>|<span data-ttu-id="01115-146">B</span><span class="sxs-lookup"><span data-stu-id="01115-146">B</span></span>|<span data-ttu-id="01115-147">E</span><span class="sxs-lookup"><span data-stu-id="01115-147">E</span></span>|<span data-ttu-id="01115-148">C</span><span class="sxs-lookup"><span data-stu-id="01115-148">C</span></span>|<span data-ttu-id="01115-149">F</span><span class="sxs-lookup"><span data-stu-id="01115-149">F</span></span>

## <a name="higher-dimensions"></a><span data-ttu-id="01115-150">Höhere Dimensionen</span><span class="sxs-lookup"><span data-stu-id="01115-150">Higher dimensions</span></span>

<span data-ttu-id="01115-151">Wenn es um mehr als zwei Dimensionen geht, ist es unhandlich, auf ein Layout als Zeilen-Haupt-oder Spalten hauptverweis zu verweisen.</span><span class="sxs-lookup"><span data-stu-id="01115-151">When it comes to greater than two dimensions, it's unwieldy to refer to a layout as either row-major or column-major.</span></span> <span data-ttu-id="01115-152">Im weiteren Verlauf dieses Themas werden z. b. Begriffe und Bezeichnungen verwendet.</span><span class="sxs-lookup"><span data-stu-id="01115-152">So, the rest of this topic uses terms and labels such as these.</span></span>

- <span data-ttu-id="01115-153">2D: die "HW" &mdash; -Höhe ist die Dimension mit der höchsten Ordnung (Row-Major).</span><span class="sxs-lookup"><span data-stu-id="01115-153">2D: "HW"&mdash;height is the highest-order dimension (row-major).</span></span>
- <span data-ttu-id="01115-154">2D: die Breite "Wh" &mdash; ist die Dimension mit der höchsten Ordnung (Spalten-Major).</span><span class="sxs-lookup"><span data-stu-id="01115-154">2D: "WH"&mdash;width is the highest-order dimension (column-major).</span></span>
- <span data-ttu-id="01115-155">3D: die Tiefe "DHW" &mdash; ist die Dimension mit der höchsten Ordnung, gefolgt von Höhe und Breite.</span><span class="sxs-lookup"><span data-stu-id="01115-155">3D: "DHW"&mdash;depth is the highest-order dimension, followed by height, and then width.</span></span>
- <span data-ttu-id="01115-156">3D: die "WHD"- &mdash; Breite ist die Dimension mit der höchsten Ordnung, gefolgt von Höhe und dann Tiefe.</span><span class="sxs-lookup"><span data-stu-id="01115-156">3D: "WHD"&mdash;width is the highest-order dimension, followed by height, and then depth.</span></span>
- <span data-ttu-id="01115-157">4D: "nchw" &mdash; die Anzahl der Bilder (Batch Größe), dann die Anzahl der Kanäle, die Höhe und die Breite.</span><span class="sxs-lookup"><span data-stu-id="01115-157">4D: "NCHW"&mdash;the number of images (batch size), then the number of channels, then height, then width.</span></span>

<span data-ttu-id="01115-158">Im Allgemeinen ist der *gepackte* Schritt einer Dimension gleich dem Produkt der Größen der Größen der unteren Reihenfolge.</span><span class="sxs-lookup"><span data-stu-id="01115-158">In general, the *packed* stride of a dimension is equal to the product of the sizes of the lower-order dimensions.</span></span> <span data-ttu-id="01115-159">Beispielsweise ist der D-Stride mit dem Layout "DHW" gleich H \* W; der H-Stride ist gleich W;. und der W-Stride ist gleich 1.</span><span class="sxs-lookup"><span data-stu-id="01115-159">For example, with a "DHW" layout, the D-stride is equal to H \* W; the H-stride is equal to W; and the W-stride is equal to 1.</span></span> <span data-ttu-id="01115-160">Die Schritte werden als *gepackt* bezeichnet, wenn die gesamte physische Größe des Mandanten gleich der Gesamtgröße des Mandanten ist. Das heißt, es gibt keine zusätzlichen Leerzeichen und keine überlappenden Elemente.</span><span class="sxs-lookup"><span data-stu-id="01115-160">Strides are said to be *packed* when the total physical size of the tensor is equal to the total logical size of the tensor; in other words, there's no extra space nor overlapping elements.</span></span>

<span data-ttu-id="01115-161">Wir erweitern das 2D-Beispiel auf drei Dimensionen, sodass wir über einen tensorflow mit der Tiefe 2, Höhe 2 und Breite 3 verfügen (insgesamt 12 logische Elemente).</span><span class="sxs-lookup"><span data-stu-id="01115-161">Let's extend the 2D example to three dimensions, so that we have a tensor with depth 2, height 2, and width 3 (for a total of 12 logical elements).</span></span>

```console
A B C
D E F

G H I
J K L
```

<span data-ttu-id="01115-162">Mit dem Layout "DHW" wird dieser tensorflow wie folgt gespeichert.</span><span class="sxs-lookup"><span data-stu-id="01115-162">With a "DHW" layout, this tensor is stored as follows.</span></span>

<span data-ttu-id="01115-163">Offset:</span><span class="sxs-lookup"><span data-stu-id="01115-163">Offset:</span></span>|<span data-ttu-id="01115-164">0</span><span class="sxs-lookup"><span data-stu-id="01115-164">0</span></span>|<span data-ttu-id="01115-165">1</span><span class="sxs-lookup"><span data-stu-id="01115-165">1</span></span>|<span data-ttu-id="01115-166">2</span><span class="sxs-lookup"><span data-stu-id="01115-166">2</span></span>|<span data-ttu-id="01115-167">3</span><span class="sxs-lookup"><span data-stu-id="01115-167">3</span></span>|<span data-ttu-id="01115-168">4</span><span class="sxs-lookup"><span data-stu-id="01115-168">4</span></span>|<span data-ttu-id="01115-169">5</span><span class="sxs-lookup"><span data-stu-id="01115-169">5</span></span>|<span data-ttu-id="01115-170">6</span><span class="sxs-lookup"><span data-stu-id="01115-170">6</span></span>|<span data-ttu-id="01115-171">7</span><span class="sxs-lookup"><span data-stu-id="01115-171">7</span></span>|<span data-ttu-id="01115-172">8</span><span class="sxs-lookup"><span data-stu-id="01115-172">8</span></span>|<span data-ttu-id="01115-173">9</span><span class="sxs-lookup"><span data-stu-id="01115-173">9</span></span>|<span data-ttu-id="01115-174">10</span><span class="sxs-lookup"><span data-stu-id="01115-174">10</span></span>|<span data-ttu-id="01115-175">11</span><span class="sxs-lookup"><span data-stu-id="01115-175">11</span></span>|
-|-|-|-|-|-|-|-|-|-|-|-|-|
<span data-ttu-id="01115-176">Wert:</span><span class="sxs-lookup"><span data-stu-id="01115-176">Value:</span></span>|<span data-ttu-id="01115-177">A</span><span class="sxs-lookup"><span data-stu-id="01115-177">A</span></span>|<span data-ttu-id="01115-178">B</span><span class="sxs-lookup"><span data-stu-id="01115-178">B</span></span>|<span data-ttu-id="01115-179">C</span><span class="sxs-lookup"><span data-stu-id="01115-179">C</span></span>|<span data-ttu-id="01115-180">D</span><span class="sxs-lookup"><span data-stu-id="01115-180">D</span></span>|<span data-ttu-id="01115-181">E</span><span class="sxs-lookup"><span data-stu-id="01115-181">E</span></span>|<span data-ttu-id="01115-182">F</span><span class="sxs-lookup"><span data-stu-id="01115-182">F</span></span>|<span data-ttu-id="01115-183">G</span><span class="sxs-lookup"><span data-stu-id="01115-183">G</span></span>|<span data-ttu-id="01115-184">H</span><span class="sxs-lookup"><span data-stu-id="01115-184">H</span></span>|<span data-ttu-id="01115-185">I</span><span class="sxs-lookup"><span data-stu-id="01115-185">I</span></span>|<span data-ttu-id="01115-186">J</span><span class="sxs-lookup"><span data-stu-id="01115-186">J</span></span>|<span data-ttu-id="01115-187">K</span><span class="sxs-lookup"><span data-stu-id="01115-187">K</span></span>|<span data-ttu-id="01115-188">L</span><span class="sxs-lookup"><span data-stu-id="01115-188">L</span></span>|

- <span data-ttu-id="01115-189">D-Stride = Height (2) \* Width (3) = 6 (z. b. der Abstand zwischen ' A ' und ' G ').</span><span class="sxs-lookup"><span data-stu-id="01115-189">D-stride = height (2) \* width (3) = 6 (for example, the distance between 'A' and 'G').</span></span>
- <span data-ttu-id="01115-190">H-Stride = Width (3) = 3 (z. b. der Abstand zwischen "A" und "d").</span><span class="sxs-lookup"><span data-stu-id="01115-190">H-stride = width (3) = 3 (for example, the distance between 'A' and 'D').</span></span>
- <span data-ttu-id="01115-191">W-Stride = 1 (z. B. der Abstand zwischen "A" und "B").</span><span class="sxs-lookup"><span data-stu-id="01115-191">W-stride = 1 (for example, the distance between 'A' and 'B').</span></span>

<span data-ttu-id="01115-192">Das Punktprodukt der Indizes/Koordinaten eines Elements und der Fortschritte gibt den Offset für dieses Element im Puffer an.</span><span class="sxs-lookup"><span data-stu-id="01115-192">The dot product of the indices/coordinates of an element and the strides provides the offset to that element in the buffer.</span></span> <span data-ttu-id="01115-193">Beispielsweise ist der Offset des H-Elements (d = 1, H = 0, w = 1) 7.</span><span class="sxs-lookup"><span data-stu-id="01115-193">For example, the offset of the H element (d=1, h=0, w=1) is 7.</span></span>

<span data-ttu-id="01115-194">{1, 0, 1} ⋅ {6, 3, 1} = 1 \* 6 + 0 \* 3 + 1 \* 1 = 7</span><span class="sxs-lookup"><span data-stu-id="01115-194">{1, 0, 1} ⋅ {6, 3, 1} = 1 \* 6 + 0 \* 3 + 1 \* 1 = 7</span></span>

## <a name="packed-tensors"></a><span data-ttu-id="01115-195">Gepackte Tensoren</span><span class="sxs-lookup"><span data-stu-id="01115-195">Packed tensors</span></span>

<span data-ttu-id="01115-196">In den obigen Beispielen werden *gepackte* Tensoren veranschaulicht.</span><span class="sxs-lookup"><span data-stu-id="01115-196">The examples above illustrate *packed* tensors.</span></span> <span data-ttu-id="01115-197">Ein tensorflow wird als *gepackt* bezeichnet, wenn die logische Größe des Tensors (in-Elementen) gleich der physischen Größe des Puffers (in-Elementen) ist und jedes Element über eine eindeutige Adresse/einen eindeutigen Offset verfügt.</span><span class="sxs-lookup"><span data-stu-id="01115-197">A tensor is said to be *packed* when the logical size of the tensor (in elements) is equal to the physical size of the buffer (in elements), and each element has a unique address/offset.</span></span> <span data-ttu-id="01115-198">Beispielsweise wird ein 2x2x3-tensorflow verpackt, wenn der Puffer 12 Elemente in der Länge hat und kein Paar von Elementen denselben Offset im Puffer gemeinsam verwenden.</span><span class="sxs-lookup"><span data-stu-id="01115-198">For example, a 2x2x3 tensor is packed if the buffer is 12 elements in length and no pair of elements share the same offset in the buffer.</span></span> <span data-ttu-id="01115-199">Gepackte Tensoren sind der häufigste Fall. in den Schritten werden jedoch komplexere Speicher Layouts ermöglicht.</span><span class="sxs-lookup"><span data-stu-id="01115-199">Packed tensors are the most common case; but strides allow more complex memory layouts.</span></span>

## <a name="broadcasting-with-strides"></a><span data-ttu-id="01115-200">Broadcasting mit Schritten</span><span class="sxs-lookup"><span data-stu-id="01115-200">Broadcasting with strides</span></span>

<span data-ttu-id="01115-201">Wenn die Puffergröße eines Tensors (in-Elemente) kleiner als das Produkt seiner logischen Dimensionen ist, folgt es, dass es einige Überlappende Elemente gibt.</span><span class="sxs-lookup"><span data-stu-id="01115-201">If a tensor's buffer size (in elements) is smaller than the product of its logical dimensions, then it follows that there must be some overlapping of elements.</span></span> <span data-ttu-id="01115-202">Der übliche Fall hierfür wird als *Broadcast* bezeichnet. Dabei sind die Elemente einer Dimension ein Duplikat einer anderen Dimension.</span><span class="sxs-lookup"><span data-stu-id="01115-202">The usual case for this is known as *broadcasting*; where the elements of a dimension are a duplicate of another dimension.</span></span> <span data-ttu-id="01115-203">Betrachten wir beispielsweise das 2D-Beispiel.</span><span class="sxs-lookup"><span data-stu-id="01115-203">For example, let's revisit the 2D example.</span></span> <span data-ttu-id="01115-204">Nehmen wir an, dass wir einen Mandanten benötigen, der logisch 2x3 ist, aber die zweite Zeile ist mit der ersten Zeile identisch.</span><span class="sxs-lookup"><span data-stu-id="01115-204">Let's say that we want a tensor that is logically 2x3, but the second row is identical to the first row.</span></span> <span data-ttu-id="01115-205">So sieht das aus.</span><span class="sxs-lookup"><span data-stu-id="01115-205">Here's how that looks.</span></span>

```console
A B C
A B C
```

<span data-ttu-id="01115-206">Diese kann als gepackter HW/Row-Major-Tensor gespeichert werden.</span><span class="sxs-lookup"><span data-stu-id="01115-206">This could be stored as a packed HW/row-major tensor.</span></span> <span data-ttu-id="01115-207">Ein kompakteres Speicher würde jedoch nur drei Elemente (a, B und C) enthalten und einen Höhen Sprung von 0 anstelle von 3.</span><span class="sxs-lookup"><span data-stu-id="01115-207">But a more compact storage would contain only 3 elements (A, B, and C) and use a height-stride of 0 instead of 3.</span></span> <span data-ttu-id="01115-208">In diesem Fall beträgt die physische Größe des Tensors 3 Elemente, die logische Größe ist jedoch 6 Elemente.</span><span class="sxs-lookup"><span data-stu-id="01115-208">In this case, the physical size of the tensor is 3 elements, but the logical size is 6 elements.</span></span>

<span data-ttu-id="01115-209">Im Allgemeinen werden alle Elemente in den Dimensionen mit niedrigerer Reihenfolge in der übertragenen Dimension wiederholt, wenn der Stride-Wert einer Dimension 0 ist. Wenn der Mandanten z. b. nchw ist und der C-Stride den Wert 0 hat, weist jeder Kanal dieselben Werte auf H und W auf.</span><span class="sxs-lookup"><span data-stu-id="01115-209">In general, if the stride of a dimension is 0, then all elements in the lower-order dimensions are repeated along the broadcasted dimension; for example, if the tensor is NCHW and the C-stride is 0, then each channel has the same values along H and W.</span></span>

## <a name="padding-with-strides"></a><span data-ttu-id="01115-210">Padding mit Schritten</span><span class="sxs-lookup"><span data-stu-id="01115-210">Padding with strides</span></span>

<span data-ttu-id="01115-211">Ein tensorflow wird als *aufgefüllt* bezeichnet, wenn die physische Größe größer ist als die minimale Größe, die für seine Elemente benötigt wird.</span><span class="sxs-lookup"><span data-stu-id="01115-211">A tensor is said to be *padded* if its physical size is larger than the minimum size needed to fit its elements.</span></span> <span data-ttu-id="01115-212">Wenn keine Broadcast-und überlappenden Elemente vorhanden sind, ist die Mindestgröße des Tensors (in Elementen) einfach das Produkt seiner Dimensionen.</span><span class="sxs-lookup"><span data-stu-id="01115-212">When there is no broadcasting nor overlapping elements, the minimum size of the tensor (in elements) is simply the product of its dimensions.</span></span> <span data-ttu-id="01115-213">Sie können die-Hilfsfunktion verwenden `DMLCalcBufferTensorSize` (Weitere Informationen finden Sie unter [directml-Hilfsfunktionen](dml-helper-functions.md) für eine Auflistung dieser Funktion), um die *minimale* Puffergröße für Ihre directml-Tensoren zu berechnen.</span><span class="sxs-lookup"><span data-stu-id="01115-213">You can use the helper function `DMLCalcBufferTensorSize` (see [DirectML helper functions](dml-helper-functions.md) for a listing of that function) to calculate the *minimum* buffer size for your DirectML tensors.</span></span>

<span data-ttu-id="01115-214">Nehmen wir an, dass ein Puffer die folgenden Werte enthält (die x-Elemente geben Füll Werte an).</span><span class="sxs-lookup"><span data-stu-id="01115-214">Let's say that a buffer contains the following values (the 'x' elements indicate padding values).</span></span>

<span data-ttu-id="01115-215">0</span><span class="sxs-lookup"><span data-stu-id="01115-215">0</span></span>|<span data-ttu-id="01115-216">1</span><span class="sxs-lookup"><span data-stu-id="01115-216">1</span></span>|<span data-ttu-id="01115-217">2</span><span class="sxs-lookup"><span data-stu-id="01115-217">2</span></span>|<span data-ttu-id="01115-218">3</span><span class="sxs-lookup"><span data-stu-id="01115-218">3</span></span>|<span data-ttu-id="01115-219">4</span><span class="sxs-lookup"><span data-stu-id="01115-219">4</span></span>|<span data-ttu-id="01115-220">5</span><span class="sxs-lookup"><span data-stu-id="01115-220">5</span></span>|<span data-ttu-id="01115-221">6</span><span class="sxs-lookup"><span data-stu-id="01115-221">6</span></span>|<span data-ttu-id="01115-222">7</span><span class="sxs-lookup"><span data-stu-id="01115-222">7</span></span>|<span data-ttu-id="01115-223">8</span><span class="sxs-lookup"><span data-stu-id="01115-223">8</span></span>|<span data-ttu-id="01115-224">9</span><span class="sxs-lookup"><span data-stu-id="01115-224">9</span></span>|
-|-|-|-|-|-|-|-|-|-|
<span data-ttu-id="01115-225">A</span><span class="sxs-lookup"><span data-stu-id="01115-225">A</span></span>|<span data-ttu-id="01115-226">B</span><span class="sxs-lookup"><span data-stu-id="01115-226">B</span></span>|<span data-ttu-id="01115-227">C</span><span class="sxs-lookup"><span data-stu-id="01115-227">C</span></span>|<span data-ttu-id="01115-228">x</span><span class="sxs-lookup"><span data-stu-id="01115-228">x</span></span>|<span data-ttu-id="01115-229">x</span><span class="sxs-lookup"><span data-stu-id="01115-229">x</span></span>|<span data-ttu-id="01115-230">D</span><span class="sxs-lookup"><span data-stu-id="01115-230">D</span></span>|<span data-ttu-id="01115-231">E</span><span class="sxs-lookup"><span data-stu-id="01115-231">E</span></span>|<span data-ttu-id="01115-232">F</span><span class="sxs-lookup"><span data-stu-id="01115-232">F</span></span>|<span data-ttu-id="01115-233">x</span><span class="sxs-lookup"><span data-stu-id="01115-233">x</span></span>|<span data-ttu-id="01115-234">x</span><span class="sxs-lookup"><span data-stu-id="01115-234">x</span></span>

<span data-ttu-id="01115-235">Der aufgefüllte tensorflow kann mithilfe eines Höhen Schrittes von 5 anstelle von 3 beschrieben werden.</span><span class="sxs-lookup"><span data-stu-id="01115-235">The padded tensor can be described by using a height-stride of 5 instead of 3.</span></span> <span data-ttu-id="01115-236">Anstelle von drei Elementen, um zur nächsten Zeile zu gelangen, ist der Schritt 5 Elemente (3 *echte* Elemente plus 2 Auffüll Elemente).</span><span class="sxs-lookup"><span data-stu-id="01115-236">Instead of stepping by 3 elements to get to the next row, the step is 5 elements (3 *real* elements plus 2 padding elements).</span></span> <span data-ttu-id="01115-237">Die Auffüll Zeichen sind z. b. in Computergrafiken üblich, um sicherzustellen, dass ein Bild über eine zweistufige Ausrichtung verfügt.</span><span class="sxs-lookup"><span data-stu-id="01115-237">Padding is common in computer graphics, for example, to ensure that an image has a power-of-two alignment.</span></span>

```console
A B C
D E F
```

## <a name="directml-buffer-tensor-descriptions"></a><span data-ttu-id="01115-238">Tensorflow-Beschreibungen für directml-Puffer</span><span class="sxs-lookup"><span data-stu-id="01115-238">DirectML buffer tensor descriptions</span></span>

<span data-ttu-id="01115-239">Directml kann mit einer Vielzahl von physischen tensorflow-Layouts arbeiten, da die [ **DML_BUFFER_TENSOR_DESC** Struktur](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) sowohl `Sizes` -als auch-Member enthält `Strides` .</span><span class="sxs-lookup"><span data-stu-id="01115-239">DirectML can work with a variety of physical tensor layouts, since the [**DML_BUFFER_TENSOR_DESC** structure](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) has both `Sizes` and `Strides` members.</span></span> <span data-ttu-id="01115-240">Einige Operator Implementierungen sind möglicherweise effizienter mit einem bestimmten Layout, sodass es nicht ungewöhnlich ist, die Speicherung von tensorflow-Daten zu ändern, um die Leistung zu verbessern.</span><span class="sxs-lookup"><span data-stu-id="01115-240">Some operator implementations might be more efficient with a specific layout, so it's not uncommon to change how tensor data is stored for better performance.</span></span>

<span data-ttu-id="01115-241">Die meisten directml-Operatoren benötigen entweder 4D-oder 5D-Tensoren, und die Reihenfolge der Größen-und Schritte Werte ist fest.</span><span class="sxs-lookup"><span data-stu-id="01115-241">Most DirectML operators require either 4D or 5D tensors, and the order of the sizes and strides values is fixed.</span></span> <span data-ttu-id="01115-242">Wenn Sie die Reihenfolge der Größen und der Stride-Werte in einer Mandanten Beschreibung beheben, kann directml unterschiedliche physische Layouts ableiten.</span><span class="sxs-lookup"><span data-stu-id="01115-242">By fixing the order of the sizes and stride values in a tensor description, it's possible for DirectML to infer different physical layouts.</span></span>

<span data-ttu-id="01115-243">**4D**</span><span class="sxs-lookup"><span data-stu-id="01115-243">**4D**</span></span>
- <span data-ttu-id="01115-244">[**DML_BUFFER_TENSOR_DESC:: sizes**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = {N-Size, C-size, H-Size, W-size}</span><span class="sxs-lookup"><span data-stu-id="01115-244">[**DML_BUFFER_TENSOR_DESC::Sizes**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = { N-size, C-size, H-size, W-size }</span></span>
- <span data-ttu-id="01115-245">[**DML_BUFFER_TENSOR_DESC::**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) Stride = {N-Stride, C-Stride, H-Stride, W-Stride}</span><span class="sxs-lookup"><span data-stu-id="01115-245">[**DML_BUFFER_TENSOR_DESC::Strides**](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc) = { N-stride, C-stride, H-stride, W-stride }</span></span>

<span data-ttu-id="01115-246">**5D**</span><span class="sxs-lookup"><span data-stu-id="01115-246">**5D**</span></span>
- <span data-ttu-id="01115-247">**DML_BUFFER_TENSOR_DESC:: sizes** = {N-Size, C-size, D-Size, H-Size, W-size}</span><span class="sxs-lookup"><span data-stu-id="01115-247">**DML_BUFFER_TENSOR_DESC::Sizes** = { N-size, C-size, D-size, H-size, W-size }</span></span>
- <span data-ttu-id="01115-248">**DML_BUFFER_TENSOR_DESC::** Stride = {N-Stride, C-Stride, D-Stride, H-Stride, W-Stride}</span><span class="sxs-lookup"><span data-stu-id="01115-248">**DML_BUFFER_TENSOR_DESC::Strides** = { N-stride, C-stride, D-stride, H-stride, W-stride }</span></span>

<span data-ttu-id="01115-249">Wenn ein directml-Operator einen 4D-oder einen 5D-Tensor erfordert, aber die tatsächlichen Daten einen niedrigeren Rang aufweisen (z. b. 2D), sollten die führenden Dimensionen mit 1 s gefüllt werden.</span><span class="sxs-lookup"><span data-stu-id="01115-249">If a DirectML operator requires a 4D or a 5D tensor, but the actual data has a smaller rank (for example, 2D), then the leading dimensions should be filled with 1s.</span></span> <span data-ttu-id="01115-250">Beispielsweise wird ein "HW"-tensorflow mithilfe von **DML_BUFFER_TENSOR_DESC:: sizes** = {1, 1, H, W} festgelegt.</span><span class="sxs-lookup"><span data-stu-id="01115-250">For example, an "HW" tensor is set using **DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, H, W }.</span></span>

<span data-ttu-id="01115-251">Wenn tensorflow-Daten in nchw/ncdhw gespeichert werden, ist es nicht erforderlich, **DML_BUFFER_TENSOR_DESC::-Schritte** festzulegen, es sei denn, Sie möchten Broadcasting oder Padding.</span><span class="sxs-lookup"><span data-stu-id="01115-251">If tensor data is stored in NCHW/NCDHW, then it's not necessary to set **DML_BUFFER_TENSOR_DESC::Strides**, unless you want broadcasting or padding.</span></span> <span data-ttu-id="01115-252">Sie können das Feld "Schritte" auf festlegen `nullptr` .</span><span class="sxs-lookup"><span data-stu-id="01115-252">You can set the strides field to `nullptr`.</span></span> <span data-ttu-id="01115-253">Wenn die tensorflow-Daten jedoch in einem anderen Layout, z. b. nhwc, gespeichert werden, benötigen Sie Schritte, um die Transformation von nchw zu diesem Layout auszudrücken.</span><span class="sxs-lookup"><span data-stu-id="01115-253">However, if the tensor data is stored in another layout, such as NHWC, then you need strides in order to express the transformation from NCHW to that layout.</span></span>

<span data-ttu-id="01115-254">Ein einfaches Beispiel ist die Beschreibung eines 2D-Tensors mit Höhe 3 und der Breite 5.</span><span class="sxs-lookup"><span data-stu-id="01115-254">For a simple example, consider the description of a 2D tensor with height 3 and width 5.</span></span>

<span data-ttu-id="01115-255">**Gepackte nchw (implizite Schritte)**</span><span class="sxs-lookup"><span data-stu-id="01115-255">**Packed NCHW (implicit strides)**</span></span>
- <span data-ttu-id="01115-256">**DML_BUFFER_TENSOR_DESC:: sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="01115-256">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="01115-257">**DML_BUFFER_TENSOR_DESC:: Schritte** = `nullptr`</span><span class="sxs-lookup"><span data-stu-id="01115-257">**DML_BUFFER_TENSOR_DESC::Strides** = `nullptr`</span></span>

<span data-ttu-id="01115-258">**Gepackte nchw (explizite Schritte)**</span><span class="sxs-lookup"><span data-stu-id="01115-258">**Packed NCHW (explicit strides)**</span></span>
- <span data-ttu-id="01115-259">N-Stride = C-size \* H-Size × W-size = 1 \* 3 \* 5 = 15</span><span class="sxs-lookup"><span data-stu-id="01115-259">N-stride = C-size \* H-size \* W-size = 1 \* 3 \* 5 = 15</span></span>
- <span data-ttu-id="01115-260">C-Stride = H-Size \* W-size = 3 \* 5 = 15</span><span class="sxs-lookup"><span data-stu-id="01115-260">C-stride = H-size \* W-size = 3 \* 5 = 15</span></span>
- <span data-ttu-id="01115-261">H-Stride = W-Size = 5</span><span class="sxs-lookup"><span data-stu-id="01115-261">H-stride = W-size = 5</span></span>
- <span data-ttu-id="01115-262">W-Stride = 1</span><span class="sxs-lookup"><span data-stu-id="01115-262">W-stride = 1</span></span>
- <span data-ttu-id="01115-263">**DML_BUFFER_TENSOR_DESC:: sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="01115-263">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="01115-264">**DML_BUFFER_TENSOR_DESC::-Schritte** = {15, 15, 5, 1}</span><span class="sxs-lookup"><span data-stu-id="01115-264">**DML_BUFFER_TENSOR_DESC::Strides** = { 15, 15, 5, 1 }</span></span>

<span data-ttu-id="01115-265">**Gepacktes nhwc**</span><span class="sxs-lookup"><span data-stu-id="01115-265">**Packed NHWC**</span></span>
- <span data-ttu-id="01115-266">N-Stride = H-Size \* W-size × C-size = 3 \* 5 \* 1 = 15</span><span class="sxs-lookup"><span data-stu-id="01115-266">N-stride = H-size \* W-size \* C-size = 3 \* 5 \* 1 = 15</span></span>
- <span data-ttu-id="01115-267">H-Stride = W-size × C-Size = 5 \* 1 = 5</span><span class="sxs-lookup"><span data-stu-id="01115-267">H-stride = W-size \* C-size = 5 \* 1 = 5</span></span>
- <span data-ttu-id="01115-268">W-Stride = C-Größe = 1</span><span class="sxs-lookup"><span data-stu-id="01115-268">W-stride = C-size = 1</span></span>
- <span data-ttu-id="01115-269">C-Stride = 1</span><span class="sxs-lookup"><span data-stu-id="01115-269">C-stride = 1</span></span>
- <span data-ttu-id="01115-270">**DML_BUFFER_TENSOR_DESC:: sizes** = {1, 1, 3, 5}</span><span class="sxs-lookup"><span data-stu-id="01115-270">**DML_BUFFER_TENSOR_DESC::Sizes** = { 1, 1, 3, 5 }</span></span>
- <span data-ttu-id="01115-271">**DML_BUFFER_TENSOR_DESC::-Schritte** = {15, 1, 5, 1}</span><span class="sxs-lookup"><span data-stu-id="01115-271">**DML_BUFFER_TENSOR_DESC::Strides** = { 15, 1, 5, 1 }</span></span>

## <a name="see-also"></a><span data-ttu-id="01115-272">Siehe auch</span><span class="sxs-lookup"><span data-stu-id="01115-272">See also</span></span>

* [<span data-ttu-id="01115-273">Directml-Hilfsfunktionen</span><span class="sxs-lookup"><span data-stu-id="01115-273">DirectML helper functions</span></span>](dml-helper-functions.md)
* [<span data-ttu-id="01115-274">DML_BUFFER_TENSOR_DESC Struktur</span><span class="sxs-lookup"><span data-stu-id="01115-274">DML_BUFFER_TENSOR_DESC structure</span></span>](/windows/desktop/api/directml/ns-directml-dml_buffer_tensor_desc)
